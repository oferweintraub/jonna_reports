{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install required packages\n",
    "%pip install pymongo python-dotenv pandas seaborn matplotlib ipython boto3 anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB\n",
      "Users to analyze: ['ptr_dvd', 'SagiBarmak']\n",
      "\n",
      "Analysis Configuration:\n",
      "Pre-war period: 2023-07-09 00:00:00 to 2023-10-07 00:00:00\n",
      "Post-war period: 2024-10-01 00:00:00 to 2024-12-30 00:00:00\n",
      "Days analyzed per period: 90\n",
      "Model: anthropic.claude-3-haiku-20240307-v1:0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from data_extractor import MongoDBExtractor\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize MongoDB extractor\n",
    "extractor = MongoDBExtractor()\n",
    "extractor.connect()\n",
    "\n",
    "# 1. Selected users for analysis (subset of 3 from config.py)\n",
    "test_users = [\n",
    "    'ptr_dvd',      # Active Kohelet Forum member\n",
    "    'SagiBarmak',   # Prominent voice\n",
    "    'KoheletForum'  # Official account\n",
    "]\n",
    "print(\"Users to analyze:\", test_users)\n",
    "\n",
    "# 2. Define analysis periods\n",
    "pre_war_end = '2023-10-07'    # Day before the war\n",
    "post_war_start = '2024-12-30'  # War start date\n",
    "days_back = 90                 # Days to analyze for each period\n",
    "\n",
    "# Create timestamp objects for reference\n",
    "pre_war_end_date = datetime.strptime(pre_war_end, '%Y-%m-%d')\n",
    "post_war_start_date = datetime.strptime(post_war_start, '%Y-%m-%d')\n",
    "\n",
    "# 3. Additional parameters\n",
    "MODEL_NAME = \"anthropic.claude-3-haiku-20240307-v1:0\"  # Current model\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "\n",
    "# Directory structure for data organization\n",
    "DATA_DIRS = {\n",
    "    'raw': os.path.join('data', 'raw'),\n",
    "    'pre_war': os.path.join('data', 'raw', 'pre_war'),\n",
    "    'post_war': os.path.join('data', 'raw', 'post_war'),\n",
    "    'analysis': os.path.join('data', 'analysis'),\n",
    "    'cleaned': os.path.join('data', 'cleaned')\n",
    "}\n",
    "\n",
    "# Create necessary directories\n",
    "for dir_path in DATA_DIRS.values():\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"\\nAnalysis Configuration:\")\n",
    "print(f\"Pre-war period: {pre_war_end_date - timedelta(days=days_back)} to {pre_war_end_date}\")\n",
    "print(f\"Post-war period: {post_war_start_date - timedelta(days=days_back)} to {post_war_start_date}\")\n",
    "print(f\"Days analyzed per period: {days_back}\")\n",
    "print(f\"Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching and cleaning data for both periods...\n",
      "\n",
      "Processing pre-war period data...\n",
      "Successfully connected to MongoDB\n",
      "Fetching tweets from 2023-07-09 00:00:00 to 2023-10-07 23:59:59\n",
      "Using timestamps from 1688850000 to 1696712399\n",
      "Fetched 190 tweets for ptr_dvd\n",
      "Fetched 161 tweets for SagiBarmak\n",
      "Saved raw data to: data\\raw\\pre_war\\tweets_pre_war_20250112_172745.csv\n",
      "\n",
      "Cleaning tweets...\n",
      "- Removing URLs\n",
      "- Removing @mentions\n",
      "- Filtering tweets with less than 7 words\n",
      "\n",
      "Tweet counts before and after cleaning:\n",
      "----------------------------------------------------------------------\n",
      "SagiBarmak           - original:  161, cleaned:  118 (removed:   43,   26.7%)\n",
      "ptr_dvd              - original:  190, cleaned:  142 (removed:   48,   25.3%)\n",
      "----------------------------------------------------------------------\n",
      "Total tweets - original: 351, after cleaning: 260\n",
      "Total removed: 91 (25.9%)\n",
      "\n",
      "Saved cleaned tweets to: data\\cleaned\\pre_war\\cleaned_pre_war_20250112_172745.csv\n",
      "Pre-war tweets after cleaning: 260\n",
      "\n",
      "Processing post-war period data...\n",
      "Successfully connected to MongoDB\n",
      "Fetching tweets from 2024-10-01 00:00:00 to 2024-12-30 23:59:59\n",
      "Using timestamps from 1727730000 to 1735595999\n",
      "Fetched 553 tweets for ptr_dvd\n",
      "Fetched 730 tweets for SagiBarmak\n",
      "Saved raw data to: data\\raw\\post_war\\tweets_post_war_20250112_172746.csv\n",
      "\n",
      "Cleaning tweets...\n",
      "- Removing URLs\n",
      "- Removing @mentions\n",
      "- Filtering tweets with less than 7 words\n",
      "\n",
      "Tweet counts before and after cleaning:\n",
      "----------------------------------------------------------------------\n",
      "SagiBarmak           - original:  730, cleaned:  567 (removed:  163,   22.3%)\n",
      "ptr_dvd              - original:  553, cleaned:  410 (removed:  143,   25.9%)\n",
      "----------------------------------------------------------------------\n",
      "Total tweets - original: 1283, after cleaning: 977\n",
      "Total removed: 306 (23.9%)\n",
      "\n",
      "Saved cleaned tweets to: data\\cleaned\\post_war\\cleaned_post_war_20250112_172746.csv\n",
      "Post-war tweets after cleaning: 977\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Fetch and Clean Data\n",
    "from tweet_cleaner import TweetCleaner\n",
    "print(\"\\nFetching and cleaning data for both periods...\")\n",
    "\n",
    "# Initialize tweet cleaner with all parameters enabled\n",
    "cleaner = TweetCleaner(min_words=7, remove_mentions=True, remove_urls=True)\n",
    "\n",
    "# Process pre-war data\n",
    "print(\"\\nProcessing pre-war period data...\")\n",
    "pre_war_df = extractor.extract_tweets_by_date_range(\n",
    "    reference_date=pre_war_end,\n",
    "    days_back=days_back,\n",
    "    usernames=test_users,\n",
    "    period_label='pre_war'\n",
    ")\n",
    "pre_war_cleaned = cleaner.clean_tweets(pre_war_df, period_label='pre_war')\n",
    "print(f\"Pre-war tweets after cleaning: {len(pre_war_cleaned)}\")\n",
    "\n",
    "# Process post-war data\n",
    "print(\"\\nProcessing post-war period data...\")\n",
    "post_war_df = extractor.extract_tweets_by_date_range(\n",
    "    reference_date=post_war_start,\n",
    "    days_back=days_back,\n",
    "    usernames=test_users,\n",
    "    period_label='post_war'\n",
    ")\n",
    "post_war_cleaned = cleaner.clean_tweets(post_war_df, period_label='post_war')\n",
    "print(f\"Post-war tweets after cleaning: {len(post_war_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced users analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing individual users for both periods...\n",
      "\n",
      "Analyzing pre-war period...\n",
      "\n",
      "Analyzing tweets for @ptr_dvd\n",
      "Total tweets: 142\n",
      "Number of batches: 3\n",
      "✓ Batch 1/3 completed\n",
      "✓ Batch 2/3 completed\n",
      "✓ Batch 3/3 completed\n",
      "\n",
      "Completed analysis for @ptr_dvd: 3 batches processed\n",
      "\n",
      "Analyzing tweets for @SagiBarmak\n",
      "Total tweets: 118\n",
      "Number of batches: 3\n",
      "✓ Batch 1/3 completed\n",
      "✓ Batch 2/3 completed\n",
      "✓ Batch 3/3 completed\n",
      "\n",
      "Completed analysis for @SagiBarmak: 3 batches processed\n",
      "\n",
      "Merging analyses for @SagiBarmak\n",
      "Total batches to analyze: 3\n",
      "\n",
      "Merging analyses for @ptr_dvd\n",
      "Total batches to analyze: 3\n",
      "\n",
      "Saved merged analysis to: data\\analysis\\pre_war\\merged_analysis_pre_war_20250112_172825.csv\n",
      "Completed basic pre-war analysis for 2 users\n",
      "\n",
      "Adding enhanced metrics for pre_war period...\n",
      "\n",
      "Analyzing enhanced metrics for @SagiBarmak\n",
      "Found 118 tweets for enhanced analysis\n",
      "\n",
      "Analyzing enhanced metrics for @SagiBarmak\n",
      "✓ Batch 1/3\n",
      "✓ Batch 2/3\n",
      "✓ Batch 3/3\n",
      "✓ Completed: 3 batches\n",
      "Total enhanced batches analyzed: 3\n",
      "\n",
      "Analyzing enhanced metrics for @ptr_dvd\n",
      "Found 142 tweets for enhanced analysis\n",
      "\n",
      "Analyzing enhanced metrics for @ptr_dvd\n",
      "✓ Batch 1/3\n",
      "✓ Batch 2/3\n",
      "✓ Batch 3/3\n",
      "✓ Completed: 3 batches\n",
      "Total enhanced batches analyzed: 3\n",
      "\n",
      "Saved enhanced analysis to: data\\analysis\\pre_war\\merged_analysis_pre_war_enhanced_20250112_172842.csv\n",
      "Completed enhanced pre-war analysis\n",
      "\n",
      "Analyzing post-war period...\n",
      "\n",
      "Analyzing tweets for @ptr_dvd\n",
      "Total tweets: 410\n",
      "Number of batches: 9\n",
      "✓ Batch 1/9 completed\n",
      "✓ Batch 2/9 completed\n",
      "✓ Batch 3/9 completed\n",
      "✓ Batch 4/9 completed\n",
      "✓ Batch 5/9 completed\n",
      "✓ Batch 6/9 completed\n",
      "✓ Batch 7/9 completed\n",
      "✓ Batch 8/9 completed\n",
      "✓ Batch 9/9 completed\n",
      "\n",
      "Completed analysis for @ptr_dvd: 9 batches processed\n",
      "\n",
      "Analyzing tweets for @SagiBarmak\n",
      "Total tweets: 567\n",
      "Number of batches: 12\n",
      "✓ Batch 1/12 completed\n",
      "✓ Batch 2/12 completed\n",
      "✓ Batch 3/12 completed\n",
      "✓ Batch 4/12 completed\n",
      "✓ Batch 5/12 completed\n",
      "✓ Batch 6/12 completed\n",
      "✓ Batch 7/12 completed\n",
      "✓ Batch 8/12 completed\n",
      "✓ Batch 9/12 completed\n",
      "✓ Batch 10/12 completed\n",
      "✓ Batch 11/12 completed\n",
      "✓ Batch 12/12 completed\n",
      "\n",
      "Completed analysis for @SagiBarmak: 12 batches processed\n",
      "\n",
      "Merging analyses for @SagiBarmak\n",
      "Total batches to analyze: 12\n",
      "\n",
      "Merging analyses for @ptr_dvd\n",
      "Total batches to analyze: 9\n",
      "\n",
      "Saved merged analysis to: data\\analysis\\post_war\\merged_analysis_post_war_20250112_173045.csv\n",
      "Completed basic post-war analysis for 2 users\n",
      "\n",
      "Adding enhanced metrics for post_war period...\n",
      "\n",
      "Analyzing enhanced metrics for @SagiBarmak\n",
      "Found 567 tweets for enhanced analysis\n",
      "\n",
      "Analyzing enhanced metrics for @SagiBarmak\n",
      "✓ Batch 1/12\n",
      "✓ Batch 2/12\n",
      "✓ Batch 3/12\n",
      "✓ Batch 4/12\n",
      "✓ Batch 5/12\n",
      "✓ Batch 6/12\n",
      "✓ Batch 7/12\n",
      "✓ Batch 8/12\n",
      "✓ Batch 9/12\n",
      "✓ Batch 10/12\n",
      "✓ Batch 11/12\n",
      "✓ Batch 12/12\n",
      "✓ Completed: 12 batches\n",
      "Total enhanced batches analyzed: 12\n",
      "\n",
      "Analyzing enhanced metrics for @ptr_dvd\n",
      "Found 410 tweets for enhanced analysis\n",
      "\n",
      "Analyzing enhanced metrics for @ptr_dvd\n",
      "✓ Batch 1/9\n",
      "✓ Batch 2/9\n",
      "✓ Batch 3/9\n",
      "✓ Batch 4/9\n",
      "✓ Batch 5/9\n",
      "✓ Batch 6/9\n",
      "✓ Batch 7/9\n",
      "✓ Batch 8/9\n",
      "✓ Batch 9/9\n",
      "✓ Completed: 9 batches\n",
      "Total enhanced batches analyzed: 9\n",
      "\n",
      "Saved enhanced analysis to: data\\analysis\\post_war\\merged_analysis_post_war_enhanced_20250112_173139.csv\n",
      "Completed enhanced post-war analysis\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Analyze Individual Users\n",
    "from analyzer import TweetAnalyzer\n",
    "from analyzer_enhanced import EnhancedTweetAnalyzer\n",
    "print(\"\\nAnalyzing individual users for both periods...\")\n",
    "\n",
    "# Initialize analyzers\n",
    "basic_analyzer = TweetAnalyzer(batch_size=50, max_retries=3)\n",
    "enhanced_analyzer = EnhancedTweetAnalyzer(batch_size=50, max_retries=3)\n",
    "\n",
    "# Process pre-war period\n",
    "print(\"\\nAnalyzing pre-war period...\")\n",
    "\n",
    "# Step 1: Basic Analysis\n",
    "pre_war_analyses = []\n",
    "for username in pre_war_cleaned['author_username'].unique():\n",
    "    user_tweets = pre_war_cleaned[pre_war_cleaned['author_username'] == username].to_dict('records')\n",
    "    analysis = basic_analyzer.analyze_user_tweets(username, user_tweets)\n",
    "    pre_war_analyses.append(analysis)\n",
    "pre_war_merged = basic_analyzer.merge_user_analyses(pd.concat(pre_war_analyses), period_label='pre_war')\n",
    "print(f\"Completed basic pre-war analysis for {len(pre_war_merged)} users\")\n",
    "\n",
    "# Step 2: Enhanced Analysis (passing both merged analysis and cleaned tweets)\n",
    "pre_war_enhanced = enhanced_analyzer.merge_user_analyses_enhanced(\n",
    "    df=pre_war_merged,\n",
    "    tweets_df=pre_war_cleaned,\n",
    "    period_label='pre_war'\n",
    ")\n",
    "print(f\"Completed enhanced pre-war analysis\")\n",
    "\n",
    "# Process post-war period\n",
    "print(\"\\nAnalyzing post-war period...\")\n",
    "\n",
    "# Step 1: Basic Analysis\n",
    "post_war_analyses = []\n",
    "for username in post_war_cleaned['author_username'].unique():\n",
    "    user_tweets = post_war_cleaned[post_war_cleaned['author_username'] == username].to_dict('records')\n",
    "    analysis = basic_analyzer.analyze_user_tweets(username, user_tweets)\n",
    "    post_war_analyses.append(analysis)\n",
    "post_war_merged = basic_analyzer.merge_user_analyses(pd.concat(post_war_analyses), period_label='post_war')\n",
    "print(f\"Completed basic post-war analysis for {len(post_war_merged)} users\")\n",
    "\n",
    "# Step 2: Enhanced Analysis (passing both merged analysis and cleaned tweets)\n",
    "post_war_enhanced = enhanced_analyzer.merge_user_analyses_enhanced(\n",
    "    df=post_war_merged,\n",
    "    tweets_df=post_war_cleaned,\n",
    "    period_label='post_war'\n",
    ")\n",
    "print(f\"Completed enhanced post-war analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users analysis report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Pre/Post War Analysis - Key Findings\n",
       "\n",
       "*Comparing Pre-war (2023-07-09 to 2023-10-07) to Post-war (2024-10-01 to 2024-12-30)*\n",
       "\n",
       "\n",
       "\n",
       "## ptr_dvd - Key Changes\n",
       "\n",
       "\n",
       "### Most Toxic Tweets\n",
       "\n",
       "\n",
       "**Pre-war Period:**\n",
       "\n",
       "```\n",
       "עלמא דשיקרא\n",
       "```\n",
       "\n",
       "```\n",
       "זו גם לא דיקטטורה. זה קרקס מדראנו בהקפאת הליכים\n",
       "```\n",
       "\n",
       "\n",
       "**Post-war Period:**\n",
       "\n",
       "```\n",
       "יהודים חמושים זו ציונות. מדיניות ממשלתית חשובה.\n",
       "```\n",
       "\n",
       "```\n",
       "פשוט שקוף שהערך העליון של אילנה דיין הוא לקבל לגיטימציה מכריסטיאן אמנפור שהיא האילנה דיין של האנטישמים בחו\n",
       "```\n",
       "\n",
       "\n",
       "### Changes in Focus\n",
       "\n",
       "**Judicial-Security Balance** (0 represents exclusive focus on security measures, while 100 represents exclusive focus on judicial reforms):\n",
       "\n",
       "\n",
       "Pre-war score: 59.0\n",
       "\n",
       "Post-war score: 50.0\n",
       "\n",
       "Change: -9.0 points\n",
       "\n",
       "\n",
       "**Rights-Security Balance** (0 represents exclusive focus on security measures, while 100 represents exclusive focus on citizen rights):\n",
       "\n",
       "\n",
       "Pre-war score: 59.0\n",
       "\n",
       "Post-war score: 52.8\n",
       "\n",
       "Change: -6.3 points\n",
       "\n",
       "\n",
       "\n",
       "### Narrative Evolution\n",
       "\n",
       "**Pre-war Top 3 Narratives:**\n",
       "\n",
       "- Promoting judicial reform and reduced government oversight\n",
       "\n",
       "- Advocating for free-market economics and privatization\n",
       "\n",
       "- Supporting Israel's Jewish national identity\n",
       "\n",
       "\n",
       "**Post-war Top 3 Narratives:**\n",
       "\n",
       "- Promoting Israel's Jewish national identity\n",
       "\n",
       "- Defending judicial reform and reduced government\n",
       "\n",
       "- Criticizing left-wing media and activists\n",
       "\n",
       "\n",
       "**Analysis of Changes:**\n",
       "\n",
       "*The user's narrative focus shifted from promoting judicial reform, free-market economics, and Israel's Jewish identity to defending judicial reform, criticizing left-wing media, and emphasizing Israel's Jewish national identity.*\n",
       "\n",
       "\n",
       "\n",
       "### Changes in Focus\n",
       "\n",
       "\n",
       "**New Entities Criticized:**\n",
       "\n",
       "- Ilana Dayan\n",
       "\n",
       "- Yair Lapid\n",
       "\n",
       "- Benny Gantz\n",
       "\n",
       "\n",
       "**No Longer Criticized:**\n",
       "\n",
       "- Pnina Tamano-Shata\n",
       "\n",
       "- Esther Hayut\n",
       "\n",
       "- Meretz party\n",
       "\n",
       "- Amir Ohana\n",
       "\n",
       "- Aaron Barak\n",
       "\n",
       "\n",
       "### Visualizations\n",
       "\n",
       "![Analysis Summary for ptr_dvd](data\\user_analysis\\analysis_ptr_dvd_20250112_180245.png)\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "## SagiBarmak - Key Changes\n",
       "\n",
       "\n",
       "### Most Toxic Tweets\n",
       "\n",
       "\n",
       "**Pre-war Period:**\n",
       "\n",
       "```\n",
       "אחרי שניגבו את הרצפה עם טל רוסו, עכשיו מגיע תורו של בני גנץ לקבל טיפול דומה.\n",
       "```\n",
       "\n",
       "```\n",
       "המטורללים האלה זוכים למכובדות ציבורית ותקשורתית ולחיבוק מהאופוזיציה.\n",
       "```\n",
       "\n",
       "\n",
       "**Post-war Period:**\n",
       "\n",
       "```\n",
       "האסלאם הרדיקלי הוא הדבר הקרוב ביותר שיש לרוע בצורתו המובהקת ביותר.\n",
       "```\n",
       "\n",
       "```\n",
       "חשיבה ביקורתית בעיני אינטלקטואלים מן השמאל זה כל הזמן לחפש ולמצוא את הנאצים שבתוכנו.\n",
       "```\n",
       "\n",
       "\n",
       "### Changes in Focus\n",
       "\n",
       "**Rights-Security Balance** (0 represents exclusive focus on security measures, while 100 represents exclusive focus on citizen rights):\n",
       "\n",
       "\n",
       "Pre-war score: 75.0\n",
       "\n",
       "Post-war score: 46.4\n",
       "\n",
       "Change: -28.6 points\n",
       "\n",
       "\n",
       "**Judicial-Security Balance** (0 represents exclusive focus on security measures, while 100 represents exclusive focus on judicial reforms):\n",
       "\n",
       "\n",
       "Pre-war score: 75.0\n",
       "\n",
       "Post-war score: 47.9\n",
       "\n",
       "Change: -27.1 points\n",
       "\n",
       "\n",
       "\n",
       "### Narrative Evolution\n",
       "\n",
       "**Pre-war Top 3 Narratives:**\n",
       "\n",
       "- Criticizing judicial activism and overreach\n",
       "\n",
       "- Defending parliamentary democracy and legislative supremacy\n",
       "\n",
       "- Opposing politicization of institutions and erosion of checks and balances\n",
       "\n",
       "\n",
       "**Post-war Top 3 Narratives:**\n",
       "\n",
       "- Promoting Israel's Jewish national identity\n",
       "\n",
       "- Opposing judicial oversight and strengthening parliamentary power\n",
       "\n",
       "- Criticizing left-wing and liberal ideologies\n",
       "\n",
       "\n",
       "**Analysis of Changes:**\n",
       "\n",
       "*The user's narrative focus evolved from defending democratic institutions and checks and balances to promoting Israel's Jewish identity, opposing judicial oversight, and criticizing left-wing ideologies.*\n",
       "\n",
       "\n",
       "\n",
       "### Changes in Focus\n",
       "\n",
       "\n",
       "**New Entities Criticized:**\n",
       "\n",
       "- Yair Lapid\n",
       "\n",
       "- Esther Hayut\n",
       "\n",
       "- Kamala Harris\n",
       "\n",
       "\n",
       "**No Longer Criticized:**\n",
       "\n",
       "- Supreme Court\n",
       "\n",
       "- Intellectual and media elites\n",
       "\n",
       "- Opposition politicians\n",
       "\n",
       "\n",
       "### Visualizations\n",
       "\n",
       "![Analysis Summary for SagiBarmak](data\\user_analysis\\analysis_SagiBarmak_20250112_180247.png)\n",
       "\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report generated successfully:\n",
      "- Report: data\\user_analysis\\analysis_report_20250112_180250.md\n",
      "- Visualizations: ['data\\\\user_analysis\\\\analysis_ptr_dvd_20250112_180245.png', 'data\\\\user_analysis\\\\analysis_SagiBarmak_20250112_180247.png']\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Generate Individual Users Report\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from individual_users_report import UserAnalysisReport\n",
    "\n",
    "# Set up plotting style\n",
    "sns.set_theme()\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Find the most recent enhanced analysis files\n",
    "pre_war_pattern = os.path.join('data', 'analysis', 'pre_war', 'merged_analysis_pre_war_enhanced_*.csv')\n",
    "post_war_pattern = os.path.join('data', 'analysis', 'post_war', 'merged_analysis_post_war_enhanced_*.csv')\n",
    "\n",
    "pre_war_files = glob.glob(pre_war_pattern)\n",
    "post_war_files = glob.glob(post_war_pattern)\n",
    "\n",
    "if not pre_war_files or not post_war_files:\n",
    "    raise FileNotFoundError(\"Enhanced analysis files not found. Please run the enhanced analysis first.\")\n",
    "\n",
    "# Get the most recent files\n",
    "pre_war_file = max(pre_war_files, key=os.path.getctime)\n",
    "post_war_file = max(post_war_files, key=os.path.getctime)\n",
    "\n",
    "# Read the enhanced analysis results\n",
    "pre_war_enhanced = pd.read_csv(pre_war_file)\n",
    "post_war_enhanced = pd.read_csv(post_war_file)\n",
    "\n",
    "# Create results dictionary\n",
    "period_results = {\n",
    "    'pre_war': pre_war_enhanced,\n",
    "    'post_war': post_war_enhanced\n",
    "}\n",
    "\n",
    "# Ensure user_analysis directory exists\n",
    "os.makedirs(os.path.join('data', 'user_analysis'), exist_ok=True)\n",
    "\n",
    "# Initialize and generate report\n",
    "report_generator = UserAnalysisReport()\n",
    "report_path, viz_path = report_generator.generate_report(\n",
    "    period_results=period_results,\n",
    "    test_users=test_users\n",
    ")\n",
    "\n",
    "print(f\"\\nReport generated successfully:\")\n",
    "print(f\"- Report: {report_path}\")\n",
    "print(f\"- Visualizations: {viz_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jonna_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
